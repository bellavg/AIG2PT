# D-VAE Configuration for AIG Generation

# Model parameters
model:
  max_n: 56  # Maximum number of nodes
  nvt: 6  # Number of vertex types (START, END, CONST0, PI, AND, PO)
  hidden_size: 256  # GRU hidden size
  latent_size: 56  # Latent space dimension
  bidirectional: false  # Use bidirectional encoder

# Training parameters
training:
  epochs: 100
  batch_size: 32
  lr: 1.0e-4
  beta: 1.0  # Weight for KL divergence
  eps_scale: 1.0  # Sampling temperature during training
  patience: 10  # For learning rate scheduling
  save_interval: 10  # Save checkpoint every N epochs

# Data parameters
data:
  data_dir: null  # Set via command line
  num_workers: 0
  
# Sampling parameters
sampling:
  num_samples: 1000
  temperature: 1.0
  use_prior: true  # Sample from N(0,I)

# Other
seed: 42
no_cuda: false
# D-VAE Baseline Configuration
# Configuration for adapting D-VAE for AIG generation

model:
  name: dvae
  hidden_dim: 128      # Hidden dimension for encoder/decoder
  latent_dim: 64       # Dimension of latent space
  max_nodes: 50        # Maximum number of nodes
  num_node_types: 3    # Number of node types (CONST0, PI, AND)

generation:
  num_samples: 100     # Number of AIGs to generate
  temperature: 1.0     # Sampling temperature for latent space
  max_nodes: 50        # Maximum AND nodes per AIG
  num_inputs: 4        # Number of primary inputs

# Training (optional - for future fine-tuning)
training:
  batch_size: 32
  learning_rate: 1.0e-3
  num_epochs: 100
  beta: 1.0            # KL divergence weight
  warmup_steps: 500
